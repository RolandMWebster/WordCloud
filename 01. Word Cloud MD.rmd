---
title: "Wine Data Word Cloud"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Outline

In this markdown document we'll walk through the process of building a wordcloud to analyse word frequency. Quite a while ago now I did a course on datacamp.com that covered frequency analysis and constructing wordclouds. I did have to go back and remind myself of a few things put that is where the techniques come from.


## Packages

As usual, these are the packages used in the R script:

```{r, warnings = FALSE, comment = FALSE, message = FALSE}
library("tidyr")
library("dplyr")
library("wordcloud")
library("tm")
```

 * We'll use tidyr and dplyr for some  simple data manipulation;

 * the tm package allows us to work with our text by creating a corpus and from there a Term Document Matrix;

 * and the wordcloud package givues us what we need to plot our wordcloud!

## Read the Data

```{r}
wine.data <- read.csv("winemag-data-130k-v2.csv",
                      stringsAsFactors = FALSE)
```

I've gathered the wine data from the following kaggle page:


It contains information on a variety of different wines. Let's take a look at what it has:

```{r}
glimpse(wine.data)
```

As mentioned, we've got all sorts of data here. We won't be using all of this, it's the description column that we're interested in. This is a character column containing a few sentences used by the wine taster to describe the wines. We'll use this column to build a word cloud that will give us some insight into which words are the most popular when describing wines. 

As a final step, We'll try using a colour scale to see if we can determine which words correlate to a good wine score and which words are more closely associated with a bad wine score.

## Reducing Data Size

The first thing we need to do is cut down the number of observations in the dataset (my laptop can't handle all these rows once we start working with the tm package functions). 

So how can we cut down our number of observations? Well, the data set contains A LOT of different grape varieties: 

```{r}
length(unique(wine.data$variety))
```

`length(unique(wine.data$variety))` different grapes! Why don't we look at a particular subset of these varieties? How about only red wines? (spoiler: that won't cut it down enough) Only the top 10 red wines? (second spoiler: my laptop will still kick up a fuss) Only the top 10 red wines from France? Well, that might just do it.

Let's get a list of the most popular red grape varieties. A bit of googling gave me the following 10 varieties:

```{r}
top.red.wines <- c("Cabernet Sauvignon", "Merlot", "Pinot Noir", "Zinfandel", "Syrah",
                   "Shiraz", "Malbec", "Tempranillo", "Sangiovese", "Barbera", "Carménère")
```

(There are 11 here but I'm told Syrah and Shiraz are the same grape so we'll bunch those toghether.)

We need to make sure these are all present in our data. Some might be missing if they commonly go by a different name or I've mispelled the grape name:

```{r}
unique(wine.data$variety[wine.data$variety %in% top.red.wines])
```

That's not all of them, we're missing "Carménère". Let's see if we can find what that is listed as in the data. We'll pull all the varieties into a vector and then use grepl() to look for the character pattern "Carm" (note we use the ^ character to only pull rows where "Carm" is at the start of the string):

```{r}
varieties <- unique(wine.data$variety)

varieties[grepl("^Carm", varieties)]
```

We've got three here. The last two are blends so we'll ignore those but the first one looks like a diferent spelling / some strange character behaviour for our grape "Carménère". We'll replace the spelling in our top.red.wines vector with the spelling in the data set:

```{r}
top.red.wines[top.red.wines == "Carménère"] <- varieties[grepl("^Carm", varieties)][1]
```

Now we can see we're matching all 11 of the varieties:

```{r}
unique(wine.data$variety[wine.data$variety %in% top.red.wines])
```

Let's filter our data so it contains only our chosen varities of grape:

```{r}
wine.data.red <- wine.data %>%
  filter(variety %in% top.red.wines)
```

How much have we reduced the size by?

```{r}
dim(wine.data.red)
```

From `dim(wine.data)[[1]]` to `dim(wine.data.red[[1]])`, not bad. Unforunately we'll have to do better, our last resort is just taking a sample of points from our current dataset.

```{r}
set.seed(1000)
sample.rows <- sample(nrow(wine.data.red))[1:10000]
wine.data.sample <- wine.data.red[sample.rows,]
```

## Getting our Data Ready

We'll start by using the corpus function to turn our description column into a corpus of text:

```{r}
wine.corpus <- Corpus(VectorSource(wine.data.sample$description))
```

Now that we've got a corpus we can start doing some tidying of the character data. We'll be using the tm_map() function to perform a few different transformations on our data. Start by converting everything to lower case:

```{r}
wine.corpus <- tm_map(wine.corpus, content_transformer(tolower))
```

... then remove all punctuation:

```{r}
wine.corpus <- tm_map(wine.corpus, removePunctuation)
```

... and eliminate white space:

```{r}
wine.corpus <- tm_map(wine.corpus, stripWhitespace)              
```

The last thing we'll do at this stage is remove stopwords. These are common words in the English language that will just be noise in our wordcloud. Words like "and" or "the", that give us no insight into that words that are often used to specifically describe wine.

```{r}
wine.corpus <- tm_map(wine.corpus, removeWords, stopwords("english"))
```

There might be some more words we want to remove that are more unique to our dataset. Once we've got our data in our desired format we'll look at removing some user chosen words.

## Term Document Matrix

Convert our Corpus into a Term Document Matrix. This will allow us to count the frequency of each word in our Corpus:

```{r}
wine.tdm <- TermDocumentMatrix(wine.corpus)          
```

Convert to a matrix for manipulation:

```{r}
wine.matrix <- as.matrix(wine.tdm)
```

Sum the rows to get a vector of frequencies. Order this vector:

```{r}
wine.vector <- sort(rowSums(wine.matrix),decreasing=TRUE)
```

Store the words and their corresponding frequencies in a data.frame.

```{r}
wine.wordcloud.data <- data.frame(word = names(wine.vector),
                                  freq = wine.vector)
```

And now let's take a look:

```{r}
head(wine.wordcloud.data,
     n = 10)
```

## Filtering on Frequency

We'll filter on a mean frequency now. We could actually do this in the wordcloud plot call but we'll apply it here since we're going to do a bit of work (using an ugly for loop so the quicker we can make it the better).

```{r}
wine.wordcloud.data <- wine.wordcloud.data %>% 
  filter(freq >= 200)
```

## Add Mean Wine Score by Word

For each word, we'll get the mean score of every wine where this word appears in the description. That way, we can get a picture of which words are used for good scoring wines and which aren't. Warning: This isn't going to be a particularly rigorous piece of analysis, it's just an inteesting addition to the wordcloud.

Let's initialize a mean points column:

```{r}
wine.wordcloud.data <- wine.wordcloud.data %>%
  mutate(mean_points = 0)
```

We'll use a for loop to find the average score for each word and bolt it on:

```{r}
for(i in wine.wordcloud.data$word){
  
  y <- wine.data.sample %>%
    filter(grepl(i, description)) %>%
    summarise(mean_points = mean(points))
  
  wine.wordcloud.data$mean_points[wine.wordcloud.data$word == i] <- y[[1]]
  
}
```

Order by mean points:

```{r}
wine.wordcloud.data <- wine.wordcloud.data %>%
  arrange(mean_points)
```

This is what we've got:

```{r}
head(wine.wordcloud.data,
     n = 10)
```


## Assigning Colours to Mean Points

We need a way to assign a colour value to our points column.


Look at the shape of the distribution of points:

```{r}
plot(wine.wordcloud.data$mean_points)
```

We were hoping for a linear distribution. This is close enough though.

Well do quite a basic (and rough) application of a colour value to each point using the colorRampPalette function:

```{r}
# Get unique values and assign a colour
colfunc <- colorRampPalette(c("red", "blue"))
```


## Wordcloud

Now we can plot our wordcloud using the wordcloud() function:

```{r}
# And let's build the wordcloud
wordcloud(words = wine.wordcloud.data$word, freq = wine.wordcloud.data$freq, 
          min.freq = 100,
          max.words=200, random.order=FALSE, rot.per=0.35,
          ordered.colors = TRUE,
          colors = colfunc(nrow(wine.wordcloud.data)))
```